import numpy as np
import pandas as pd
import keras
from keras.applications.inception_v3 import InceptionV3
from keras.models import Model
from keras.layers import Dense, Dropout, Flatten
import os
#from tqdm import tqdm
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
import cv2
from subprocess import check_output
import os


# In[107]:


os.getcwd()


# In[108]:


df_train = pd.read_csv('/home/ubuntu/labels.csv')
df_test = pd.read_csv('/home/ubuntu/sample_submission.csv')


# In[109]:


targets_series = pd.Series(df_train['breed'])
one_hot = pd.get_dummies(targets_series, sparse = True)


# In[110]:


one_hot_labels = np.asarray(one_hot)


# In[111]:


im_size = 256 #image size is changable up to 224
x_train = []
y_train = []
x_test = []


# In[112]:


i = 0 
for f, breed in df_train.values:
    img = cv2.imread('/home/ubuntu/train_new/{}.jpg'.format(f))
    #print(img)
    label = one_hot_labels[i]
    img=cv2.resize(img,(256,256),interpolation=cv2.INTER_AREA)
    print(img.shape[:2])
    #print(img)
    #x_train.append(cv2.resize(img, (90, 90)))
    x_train.append(img)
    y_train.append(label)
    #y_train.append(label)
    i += 1
    


# In[113]:


for f in df_test['id'].values:
    img = cv2.imread('/home/ubuntu/test/{}.jpg'.format(f))
    img=cv2.resize(img,(256,256),interpolation=cv2.INTER_AREA)
    print(img.shape[:2])
    x_test.append(img)


# In[114]:


y_train_raw = np.array(y_train, np.uint8)
x_train_raw = np.array(x_train, np.float32) / 255.
x_test  = np.array(x_test, np.float32) / 255.


# In[115]:


num_class = y_train_raw.shape[1]


# In[116]:


X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.3, random_state=42)


# In[117]:


#base_model = VGG19(weights = 'imagenet', include_top=False, input_shape=(im_size, im_size, 3))

base_model = InceptionV3(weights = 'imagenet', include_top=False, input_shape=(im_size, im_size, 3))


# In[120]:


x = base_model.output
x = Flatten()(x)

x = Dense(512, activation='relu', name='extra_layer_2')(x)
x = Dense(256, activation='relu', name='extra_layer_3')(x)
#x = Dropout(0.5)(x)
predictions = Dense(num_class, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)
for layer in base_model.layers:
    layer.trainable = False

    
model.compile(loss='categorical_crossentropy', 
              optimizer='sgd', 
              metrics=['accuracy'])

callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]
model.summary()


# In[121]:


model.fit(X_train, Y_train, epochs=25, validation_data=(X_valid, Y_valid), verbose=1)


# In[122]:


preds = model.predict(x_test, verbose=1)


# In[123]:


sub = pd.DataFrame(preds)
# Set column names to those generated by the one-hot encoding earlier
col_names = one_hot.columns.values
sub.columns = col_names
# Insert the column id from the sample_submission at the start of the data frame
sub.insert(0, 'id', df_test['id'])
sub.head(5)
sub.to_csv('/home/ubuntu/final.csv', index=True, header=True)

